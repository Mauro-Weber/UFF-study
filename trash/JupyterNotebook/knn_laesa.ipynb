{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ce9a811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import DoubleType, ArrayType, FloatType, StructType, StructField, IntegerType\n",
    "from pyspark.sql.functions import spark_partition_id, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40b6bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## the distance function\n",
    "from scipy.spatial import distance\n",
    "## creates the feature vector\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "## import numpy\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.sql.functions import max, abs, min, when\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a21b279c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/06 23:58:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "## start session\n",
    "spark = SparkSession.builder.appName(\"SparkRandomCoordinatesDataset\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6284fc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpleF(oq):\n",
    "    return F.udf(lambda x: float(distance.euclidean(x, oq)), DoubleType())\n",
    "\n",
    "##DEFINES A UDF FROM L2DIST THE DATAFRAME FROM A QUERY SET\n",
    "distance_udf = F.udf(lambda x,y: float(distance.euclidean(x, y)), DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af4d1b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "## defines query object and \n",
    "oq = [np.random.rand(1)[0],np.random.rand(1)[0]]\n",
    "\n",
    "#oq = [5.0,5.0]\n",
    "\n",
    "k = 10\n",
    "\n",
    "\n",
    "pivot = [np.random.rand(1)[0],np.random.rand(1)[0]]\n",
    "\n",
    "#pivots = [(i+1,[np.random.rand(1).round(5)[0],np.random.rand(1).round(5)[0]]) for i in range(2)]\n",
    "#pvt1 = [0.0,0.0]\n",
    "\n",
    "dist_pivot_oq = distance.euclidean(pivot,oq) \n",
    "\n",
    "#pvtColumns = [\"idPvt\",\"fvPvt\"]\n",
    "#pvtDF = spark.createDataFrame(data=pivots, schema = pvtColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d339df75",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the dataset (local)\n",
    "\n",
    "#data = [(1,0.12,0.25),(2,0.85,0.75),(3,0.18,0.15),(4,8.1,7.1),(5,5.6,6.9),(6,3.6,4.9),(7,2.1,4.9),(8,8.6,3.9)]\n",
    "\n",
    "#schema = [\"id\",\"coord_x\",\"coord_y\"]\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"coord_x\", FloatType(), True),\n",
    "    StructField(\"coord_y\", FloatType(), True)])\n",
    "\n",
    "\n",
    "#df = spark.createDataFrame(data = data, schema = schema)\n",
    "df = spark.read.csv(\"/home/weber/Documents/coordDF2.csv\",schema=schema)\n",
    "\n",
    "##SMALL SANITY CHECK - @PRODUCTION TESTAR LOADING\n",
    "df = df.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89007ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the struct for the dimensional feature vector\n",
    "cNames = df.columns\n",
    "cNames.remove(\"id\")\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=cNames,\n",
    "    outputCol=\"fv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2cd35a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## appends the fv into the dataframe as column\n",
    "df = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b257803d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5960/4268435456.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "113889e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.withColumn(f'distances_oi_pivot', simpleF(pivot)(F.col('fv')))\n",
    "#df_new.repartition(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e93b91fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 2:>                                                          (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------+--------------------+-------------------+--------------------+\n",
      "| id|coord_x|coord_y|                  fv|     distances_pvt1| |d(oq,p1)-d(oi,p1)||\n",
      "+---+-------+-------+--------------------+-------------------+--------------------+\n",
      "| 95|0.71852|0.57866|[0.71851998567581...|0.48866349684393884|0.006295020710815502|\n",
      "|  5|0.49794|0.54987|[0.49794000387191...| 0.5042247550866347|0.009266237531880328|\n",
      "| 84| 0.4196|0.53659|[0.41960000991821...| 0.5299143757171434| 0.03495585816238905|\n",
      "| 23|0.33079|0.35678|[0.33079001307487...| 0.4595715198475419| 0.03538699770721243|\n",
      "| 90|0.57788| 0.5282|[0.57788002490997...|0.45612942342265983| 0.03882909413209451|\n",
      "| 92|0.74659|0.53865|[0.74659001827239...|0.45038234059071536| 0.04457617696403898|\n",
      "| 63|0.66367|0.53602|[0.66367000341415...|0.44776357588848714|  0.0471949416662672|\n",
      "|  3|0.19594|0.30892|[0.19594000279903...| 0.5541855637868418|0.059227046232087466|\n",
      "| 97|0.14923|0.05248|[0.14923000335693...| 0.5571768984731591| 0.06221838091840476|\n",
      "| 43|0.17764|0.28744|[0.17764000594615...| 0.5631671174722319| 0.06820859991747757|\n",
      "| 85|0.89244| 0.6258|[0.89244002103805...| 0.5674273899700267| 0.07246887241527239|\n",
      "| 15|0.69567| 0.6582|[0.69567000865936...| 0.5680987949922194| 0.07314027743746504|\n",
      "| 57|0.29835|0.19126|[0.29835000634193...|0.41915048449268766| 0.07580803306206668|\n",
      "| 41|0.37885|0.35039|[0.37885001301765...|0.41733423938085046| 0.07762427817390388|\n",
      "| 98|0.70148|0.50562|[0.70147997140884...|0.41545603689295013| 0.07950248066180421|\n",
      "| 16|0.36876|0.56382|[0.36875998973846...| 0.5809299765300822| 0.08597145897532782|\n",
      "| 42|0.57835|0.47667|[0.57835000753402...|0.40675260816968284|  0.0882059093850715|\n",
      "| 96|0.37698|0.57437|[0.37698000669479...| 0.5849123010793338| 0.08995378352457944|\n",
      "| 71|0.48539|0.42879|[0.48539000749588...| 0.4036612422302649| 0.09129727532448945|\n",
      "| 65|0.29393|0.51949|[0.29392999410629...| 0.5944682699907858|  0.0995097524360315|\n",
      "+---+-------+-------+--------------------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 2:====================================>                      (5 + 3) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_with_dist = df_new.withColumn(\"|d(oq,p1)-d(oi,p1)|\", \\\n",
    "    abs (dist_pvt1_oq - \\\n",
    "    F.col('distances_oi_pivot')))\n",
    "\n",
    "df_with_dist = df_with_dist.orderBy(\"|d(oq,p1)-d(oi,p1)|\")\n",
    "\n",
    "df_2 = df_with_dist.repartitionByRange(20, col('|d(oq,p1)-d(oi,p1)|'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1efd130",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new = df_new.withColumn(\"partition_id\", spark_partition_id()\n",
    "\n",
    "def knn_laesa(dataframe, oq, k):\n",
    "    \n",
    "    for i in range(df_new2.rdd.getNumPartitions()):\n",
    "\n",
    "        if i == 0:\n",
    "            ## PART_ONE\n",
    "            df_part0 = df_new2.where(spark_partition_id() == i).localCheckpoint()\n",
    "            df_part0_new = df_part0.withColumn(\"dist_Oq\", simpleF(oq)(F.col('fv')))\n",
    "            df_part0_new = df_part0_new.orderBy(\"dist_Oq\").limit(k)\n",
    "            max_value2 = df_part0_new.agg(max('dist_Oq')).collect()[0][0]\n",
    "\n",
    "        else:\n",
    "            ## PART_TWO\n",
    "\n",
    "            df_parti = df_new2.filter(spark_partition_id() == i).localCheckpoint()\n",
    "            df_parti = df_parti.where(df_parti[\"|d(oq,p1)-d(oi,p1)|\"] <= max_value2)\n",
    "            df_parti_new = df_part1.withColumn(\"dist_Oq\", simpleF(oq)(F.col('fv')))\n",
    "\n",
    "\n",
    "\n",
    "            ## PART_THREE\n",
    "            df_part0_new = df_part0_new.union(df_parti_new).orderBy(\"dist_Oq\").limit(k).localCheckpoint()\n",
    "            max_value2 = df_part0_new.agg(max('dist_Oq')).collect()[0][0]\n",
    "    return(df_part0_new)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05c89e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------+--------------------+-------------------+--------------------+-------------------+\n",
      "| id|coord_x|coord_y|                  fv|     distances_pvt1| |d(oq,p1)-d(oi,p1)||            dist_Oq|\n",
      "+---+-------+-------+--------------------+-------------------+--------------------+-------------------+\n",
      "| 23|0.33079|0.35678|[0.33079001307487...| 0.4595715198475419| 0.03538699770721243|  0.054694271806931|\n",
      "| 41|0.37885|0.35039|[0.37885001301765...|0.41733423938085046| 0.07762427817390388|0.07906928649899292|\n",
      "| 65|0.29393|0.51949|[0.29392999410629...| 0.5944682699907858|  0.0995097524360315|0.11348251135535493|\n",
      "| 45|0.40363|0.31745|[0.40362998843193...| 0.3775631125213736| 0.11739540503338075|0.12026322263944784|\n",
      "|  4|0.21342|0.44719|[0.21342000365257...| 0.6076469790228931| 0.11268846146813877|  0.120593966299579|\n",
      "| 84| 0.4196|0.53659|[0.41960000991821...| 0.5299143757171434| 0.03495585816238905|0.15475090478026468|\n",
      "| 16|0.36876|0.56382|[0.36875998973846...| 0.5809299765300822| 0.08597145897532782|0.15759549973232473|\n",
      "| 71|0.48539|0.42879|[0.48539000749588...| 0.4036612422302649| 0.09129727532448945|0.15775808079777157|\n",
      "|  3|0.19594|0.30892|[0.19594000279903...| 0.5541855637868418|0.059227046232087466|0.16764343909841595|\n",
      "| 46| 0.2989|0.57749|[0.29890000820159...| 0.6344240026660601|  0.1394654851113058|0.16869324216363424|\n",
      "+---+-------+-------+--------------------+-------------------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_part0_new.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b78d228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure the execution time of the function\n",
    "start_time = time.time()\n",
    "result = my_function(df)\n",
    "end_time = time.time()\n",
    "\n",
    "# print the execution time\n",
    "print(\"Execution time:\", end_time - start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
